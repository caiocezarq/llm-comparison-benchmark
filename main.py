#!/usr/bin/env python3
"""
Pipeline de Compara√ß√£o de Modelos de Linguagem
Script principal para executar o pipeline completo.
"""
import sys
import os
import time
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

# Adicionar o diret√≥rio atual ao path para importar o m√≥dulo src
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.pipeline import run_pipeline, evaluate_and_export, generate_final_report
from src.utils import get_next_result_folder
from src.config import get_config, ConfigValidator
from src.logger import get_logger, log_execution_start, log_execution_end, log_configuration, log_statistics

# =============================================================================
# CONFIGURA√á√ïES DE EXECU√á√ÉO
# =============================================================================
# Carregar configura√ß√µes centralizadas
config = get_config()

# Validar configura√ß√µes
try:
    ConfigValidator.validate_all()
    print("‚úÖ Configura√ß√µes validadas com sucesso")
except ValueError as e:
    print(f"‚ùå Erro na configura√ß√£o: {e}")
    sys.exit(1)

# Configurar logger
logger = get_logger("main")
# =============================================================================

def main():
    """
    Fun√ß√£o principal para executar o pipeline m√∫ltiplas vezes.
    """
    print("üöÄ PIPELINE DE COMPARA√á√ÉO DE MODELOS DE LINGUAGEM")
    print("=" * 60)
    print("üìä Modelos suportados: Groq + Google Gemini")
    print("üéØ M√©tricas: BLEU, ROUGE, BERTScore, EvidentlyAI")
    if config.INCLUDE_BENCHMARKS:
        print("üèÜ Benchmarks: MMLU, HellaSwag")
    print("=" * 60)
    print(f"üîÑ Execu√ß√µes configuradas: {config.NUMERO_EXECUCOES}")
    print(f"‚è±Ô∏è  Timeout entre execu√ß√µes: {config.TIMEOUT_ENTRE_EXECUCOES}s")
    if config.INCLUDE_BENCHMARKS:
        print(f"üèÜ Benchmarks inclu√≠dos: {config.INCLUDE_BENCHMARKS}")
    print("=" * 60)
    
    # Log das configura√ß√µes
    log_configuration(logger, {
        "NUMERO_EXECUCOES": config.NUMERO_EXECUCOES,
        "TIMEOUT_ENTRE_EXECUCOES": config.TIMEOUT_ENTRE_EXECUCOES,
        "TIMEOUT_ENTRE_PERGUNTAS": config.TIMEOUT_ENTRE_PERGUNTAS,
        "PASTA_RESULTADOS": config.PASTA_RESULTADOS,
        "PREFIXO_EXECUCAO": config.PREFIXO_EXECUCAO
    })
    
    execucoes_sucesso = 0
    execucoes_erro = 0
    tempo_inicio_total = time.time()
    
    for execucao in range(1, config.NUMERO_EXECUCOES + 1):
        print(f"\nüîÑ EXECU√á√ÉO {execucao}/{config.NUMERO_EXECUCOES}")
        print("-" * 40)
        
        # Log do in√≠cio da execu√ß√£o
        log_execution_start(logger, execucao, config.NUMERO_EXECUCOES)
        
        try:
            tempo_inicio = time.time()
            
            # Criar pasta individual para esta execu√ß√£o
            result_folder = get_next_result_folder()
            print(f"üìÅ Resultados da execu√ß√£o {execucao} ser√£o salvos em: {result_folder}")
            
            # Executar pipeline
            df = run_pipeline(include_benchmarks=config.INCLUDE_BENCHMARKS)
            
            tempo_execucao = time.time() - tempo_inicio
            
            if df is not None and not df.empty:
                execucoes_sucesso += 1
                print(f"‚úÖ Execu√ß√£o {execucao} conclu√≠da com sucesso!")
                print(f"üìä Total de resultados: {len(df)}")
                print(f"ü§ñ Modelos testados: {df['model'].nunique()}")
                print(f"üìù Prompts executados: {df['prompt'].nunique()}")
                print(f"‚è±Ô∏è  Tempo de execu√ß√£o: {tempo_execucao:.2f}s")
                
                # Mostrar estat√≠sticas b√°sicas
                print(f"üìà Tempo m√©dio por resposta: {df['time'].mean():.2f}s")
                print(f"üìè Comprimento m√©dio das respostas: {df['prediction'].str.len().mean():.0f} caracteres")
                
                # Mostrar modelos com sucesso
                success_models = df[~df['is_error']]['model'].unique()
                print(f"‚úÖ Modelos funcionando: {len(success_models)}")
                
                # Mostrar modelos com erro
                error_models = df[df['is_error']]['model'].unique()
                error_count = df['is_error'].sum()
                if len(error_models) > 0:
                    print(f"‚ùå Modelos com erro: {len(error_models)}")
                    print(f"üìä Total de erros: {error_count}/{len(df)} ({(error_count/len(df)*100):.1f}%)")
                
                # Salvar resultados da execu√ß√£o
                print(f"üíæ Salvando resultados da execu√ß√£o {execucao}...")
                try:
                    # Exporta resultados das APIs (sem c√°lculos de m√©tricas)
                    stats = evaluate_and_export(df, result_folder)
                    
                    # Gera relat√≥rio b√°sico da pipeline
                    report_json, report_txt = generate_final_report(df, stats, {}, tempo_execucao, result_folder)
                    
                    print(f"‚úÖ Resultados salvos com sucesso!")
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao salvar resultados: {e}")
                
                # Log do fim da execu√ß√£o (sucesso)
                log_execution_end(logger, execucao, True, tempo_execucao)
                
            else:
                execucoes_erro += 1
                print(f"‚ùå Execu√ß√£o {execucao} falhou: Nenhum resultado foi gerado")
                
                # Log do fim da execu√ß√£o (erro)
                log_execution_end(logger, execucao, False, tempo_execucao)
                
        except Exception as e:
            execucoes_erro += 1
            print(f"‚ùå Erro na execu√ß√£o {execucao}: {e}")
            
            # Log do fim da execu√ß√£o (erro)
            log_execution_end(logger, execucao, False, time.time() - tempo_inicio)
        
        # Aguardar entre execu√ß√µes (exceto na √∫ltima)
        if execucao < config.NUMERO_EXECUCOES:
            print(f"\n‚è≥ Aguardando {config.TIMEOUT_ENTRE_EXECUCOES}s antes da pr√≥xima execu√ß√£o...")
            time.sleep(config.TIMEOUT_ENTRE_EXECUCOES)
    
    # Resumo final
    tempo_total = time.time() - tempo_inicio_total
    print("\n" + "=" * 60)
    print("üìã RESUMO FINAL DAS EXECU√á√ïES")
    print("=" * 60)
    print(f"‚úÖ Execu√ß√µes bem-sucedidas: {execucoes_sucesso}/{config.NUMERO_EXECUCOES}")
    print(f"‚ùå Execu√ß√µes com erro: {execucoes_erro}/{config.NUMERO_EXECUCOES}")
    print(f"‚è±Ô∏è  Tempo total: {tempo_total:.2f}s ({tempo_total/60:.1f} minutos)")
    print(f"üìà Taxa de sucesso: {(execucoes_sucesso/config.NUMERO_EXECUCOES)*100:.1f}%")
    
    # Estat√≠sticas de erros se houver execu√ß√µes bem-sucedidas
    if execucoes_sucesso > 0:
        print(f"\nüìä AN√ÅLISE DE ERROS:")
        print(f"üí° Verifique os arquivos 'relatorio_erros.json' e 'relatorio_erros.txt' para detalhes")
        print(f"üìÅ Pasta de resultados: {result_folder}")
    
    # Log das estat√≠sticas finais
    log_statistics(logger, {
        "execucoes_sucesso": execucoes_sucesso,
        "execucoes_erro": execucoes_erro,
        "tempo_total": f"{tempo_total:.2f}s",
        "taxa_sucesso": f"{(execucoes_sucesso/config.NUMERO_EXECUCOES)*100:.1f}%"
    })
    
    if execucoes_sucesso > 0:
        print(f"\nüìÅ Resultados salvos na pasta: {result_folder}")
        # Executar an√°lise consolidada se houver execu√ß√µes bem-sucedidas
        if execucoes_sucesso > 0:
            print("\nüî¨ Iniciando an√°lise consolidada...")
            try:
                from analysis.analysis import executar_analise
                resultado_analise = executar_analise()
                if resultado_analise:
                    print("‚úÖ An√°lise consolidada conclu√≠da com sucesso!")
                else:
                    print("‚ö†Ô∏è An√°lise consolidada n√£o p√¥de ser executada")
            except Exception as e:
                print(f"‚ùå Erro na an√°lise consolidada: {e}")
        else:
            print("üí° Execute mais execu√ß√µes para permitir an√°lise consolidada")
        
        print(f"üéØ An√°lise executada com {execucoes_sucesso} execu√ß√µes bem-sucedidas")
    
    return 0 if execucoes_sucesso > 0 else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
